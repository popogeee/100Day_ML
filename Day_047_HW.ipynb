{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "#lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "#lgb_val要用lgb.cv進行設定才會有cross validation的效果，lgb_val只是切下固定大小的training set作為validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊的設定是for mulituclass，尚未進行optimization的參數\n",
    "params_lightGB = {\n",
    "    'task': 'train',\n",
    "    'objective':'multiclass',\n",
    "    'boosting': 'gbdt',\n",
    "    'min_data_in_leaf':40,\n",
    "    'metric': 'multi_logloss',\n",
    "    'metric_freq':50,\n",
    "    'max_depth':10,\n",
    "    'num_leaves': 70,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_class':10,\n",
    "    'verbose':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#設定cross validation的參數，部分的參數follow 上面的params_lightGB參數\n",
    "cv_results = lgb.cv(\n",
    "    params_lightGB, train_set=lgb_train, num_boost_round=10000, nfold=5,\n",
    "    shuffle=True, stratified=True, verbose_eval=None, early_stopping_rounds=100)\n",
    "\n",
    "# verbose_eval設定為沒幾個evaluation會出現一次數值，沒必要使用\n",
    "# classification using stratified, if regression set False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nround = np.argmin(cv_results['multi_logloss-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1255"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#求出上面這些參數能夠得到最佳解的round是多少？\n",
    "nround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#開始真正的訓練\n",
    "gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_score: 0.9777777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       0.93      0.97      0.95        39\n",
      "           2       1.00      1.00      1.00        35\n",
      "           3       0.97      0.97      0.97        35\n",
      "           4       1.00      0.95      0.97        38\n",
      "           5       1.00      1.00      1.00        39\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.95      1.00      0.97        37\n",
      "           8       1.00      0.91      0.96        35\n",
      "           9       0.94      0.97      0.95        30\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#np.argmax( )参数返回的是沿轴axis最大值的索引值\n",
    "#refer to https://blog.csdn.net/qq1483661204/article/details/78959293\n",
    "\n",
    "y_pred = gbm.predict(X_test) #這個是機率值\n",
    "y_pred_1 = [np.argmax(line) for line in y_pred] \n",
    "#共有360次猜測，每次猜測共有10個類別(0~9)，所以有10個機率值，從中選出最大機率值所對應的索引值，就是gbm所預測的值\n",
    "\n",
    "test_acc_score = metrics.accuracy_score(y_test, y_pred_1) #拿實際值與gbm所預測的值做比較\n",
    "print(\"val_acc_score:\", test_acc_score)\n",
    "\n",
    "test_acc = metrics.classification_report(y_test, y_pred_1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearchCV引數說明，clf1設定訓練的學習器\n",
    "#param_dist字典型別，放入引數搜尋範圍\n",
    "#scoring = 'neg_log_loss'，精度評價方式設定為“neg_log_loss“\n",
    "#n_iter=300，訓練300次，數值越大，獲得的引數精度越大，但是搜尋時間越長\n",
    "#n_jobs = -1，使用所有的CPU進行訓練，預設為1，使用1個CPU\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 144 is smaller than n_iter=150. Running 144 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 35,\n",
       " 'min_data_in_leaf': 15,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.23333333333333334}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hw = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    hw.data, hw.target, test_size=0.20)\n",
    "param_grid_dist = {\n",
    "        'min_data_in_leaf':range(5,20,5),\n",
    "        'max_depth':range(5,20,5),\n",
    "        'learning_rate':np.linspace(0.1,0.5,num=4),\n",
    "        'num_leaves':range(30,50,5)\n",
    "        }\n",
    "clf = lgb.LGBMClassifier()\n",
    "grid = RandomizedSearchCV(\n",
    "    clf,param_grid_dist,cv=5,scoring='neg_log_loss',n_iter=150,n_jobs = -1)\n",
    "\n",
    "search = grid.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊的設定是for mulituclass\n",
    "params_lightGB = {\n",
    "    'task': 'train',\n",
    "    'objective':'multiclass',\n",
    "    'boosting': 'gbdt',\n",
    "    'min_data_in_leaf':search.best_params_[\"min_data_in_leaf\"],\n",
    "    'metric': 'multi_logloss',\n",
    "    'metric_freq':50,\n",
    "    'max_depth':search.best_params_[\"max_depth\"],\n",
    "    'num_leaves':search.best_params_[\"num_leaves\"],\n",
    "    'learning_rate':0.1,\n",
    "    'num_class':10,\n",
    "    'verbose':None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "#設定cross validation的參數，部分的參數follow 上面的params_lightGB參數\n",
    "cv_results = lgb.cv(\n",
    "    params_lightGB, train_set=lgb_train, num_boost_round=10000, nfold=5,\n",
    "    shuffle=True, stratified=True, verbose_eval=None, early_stopping_rounds=100)\n",
    "\n",
    "# verbose_eval設定為沒幾個evaluation會出現一次數值，沒必要使用\n",
    "# classification using stratified, if regression set False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n"
     ]
    }
   ],
   "source": [
    "nround = np.argmin(cv_results['multi_logloss-mean'])\n",
    "print(nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=nround)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_score: 0.9638888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       0.95      0.98      0.96        41\n",
      "           2       0.97      0.97      0.97        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.92      0.97      0.94        35\n",
      "           5       0.93      0.97      0.95        29\n",
      "           6       1.00      0.94      0.97        35\n",
      "           7       0.95      0.97      0.96        36\n",
      "           8       0.98      0.89      0.93        46\n",
      "           9       0.97      0.97      0.97        31\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.97      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#np.argmax( )参数返回的是沿轴axis最大值的索引值\n",
    "#refer to https://blog.csdn.net/qq1483661204/article/details/78959293\n",
    "\n",
    "y_pred = gbm.predict(X_test) #這個是機率值\n",
    "y_pred_1 = [np.argmax(line) for line in y_pred] \n",
    "#共有360次猜測，每次猜測共有10個類別(0~9)，所以有10個機率值，從中選出最大機率值所對應的索引值，就是gbm所預測的值\n",
    "\n",
    "test_acc_score = metrics.accuracy_score(y_test, y_pred_1) #拿實際值與gbm所預測的值做比較\n",
    "print(\"val_acc_score:\", test_acc_score)\n",
    "\n",
    "test_acc = metrics.classification_report(y_test, y_pred_1)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
